{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/\u001b[0m\n",
      "├── \u001b[01;34mllm-papers\u001b[0m\n",
      "│   └── openai-paper.pdf\n",
      "├── \u001b[01;34mssi-docs\u001b[0m\n",
      "│   ├── boe-ssi.pdf\n",
      "│   └── db-ssi.pdf\n",
      "└── \u001b[01;34msystem-documentation\u001b[0m\n",
      "    ├── pandas-basics.html\n",
      "    ├── pandas-cookbook.html\n",
      "    └── pandas-ten-minutes.html\n",
      "\n",
      "3 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "!tree data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings #uses llama2 embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## system-documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = BSHTMLLoader(\"data/system-documentation/pandas-basics.html\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='Essential basic functionality — pandas 2.2.2 documentation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n    Back to top\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Site Navigation\\n  \\n\\n\\n\\n                        Getting started\\n                      \\n\\n\\n\\n                        User Guide\\n                      \\n\\n\\n\\n                        API reference\\n                      \\n\\n\\n\\n                        Development\\n                      \\n\\n\\n\\n                        Release notes\\n                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub\\n\\n\\n\\nTwitter\\n\\n\\n\\nMastodon\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Site Navigation\\n  \\n\\n\\n\\n                        Getting started\\n                      \\n\\n\\n\\n                        User Guide\\n                      \\n\\n\\n\\n                        API reference\\n                      \\n\\n\\n\\n                        Development\\n                      \\n\\n\\n\\n                        Release notes\\n                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub\\n\\n\\n\\nTwitter\\n\\n\\n\\nMastodon', metadata={'source': 'data/system-documentation/pandas-basics.html', 'title': 'Essential basic functionality — pandas 2.2.2 documentation'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)\n",
    "all_splits[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    collection_name=\"system-documentation\",\n",
    "    embedding=OllamaEmbeddings(),\n",
    "    collection_metadata={\"topic\":\"system documentation\",\"source\": \"pandas-basics.html\"},\n",
    "    persist_directory=\"./chroma_db_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ssi-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssi_loader = PyPDFLoader(\"data/ssi-docs/db-ssi.pdf\")\n",
    "ssi_pages = ssi_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='Deutsche Bank AG, Frankfurt Cash Equities    \\n                           \\n \\n  \\n1 | P a g e   \\nJanuary 2021  \\n For internal use only                         Standard Settlement Instructions   \\n  \\nDEUTDEFFEEQ  is the Beneficiary BIC and 7LTWFZYICNSX8D621K86  is the Legal Entity  \\nIdentifier (LEI) for all the following accounts   \\n  \\n  \\n  \\nCOUNTRY                SETTLEMENT INSTRUCTIONS                      SWIFT CODE   \\n  \\nARGENTINA                    Industrial & Commercial Bank of China (ARG)                        ICBKARBAGCD                                                                   \\nA/C 367963 (stock)  \\n                                         Place of settlement = CAVLARBAXXX  \\n                                      \\n  \\n  \\nAUSTRALIA                    National Australian Bank                                                            NATAAU3303X                                          \\nCHESS PID 20006  \\n                 Austraclear Code NNLM  \\n                 A/C 26965 (stock)  \\n                                        Place of Settlement = CAETAU21XXX  \\n  \\n  \\n  \\nAUSTRIA                         Deutsche Bank AG, Frankfurt                                                    DEUTDEFFCUS                                           \\n                                         Place of settlement = OCSDATWWXXX  \\n               Stock A/C 100970228301  \\n  \\n  \\n  \\nBAHRAIN                        HSBC Bank Middle East –  Manama                               BBMEBHBXXXX  \\n                                         A/C 001-126978-085 (stock)  \\n                                         Place of settlement = XBAHBHB1XXX  \\n                                         Use Beneficiary BIC - DEUTGB22EEQ  \\n  \\n  \\n  \\nBELGIUM                         Deutsche Bank AG Amsterdam                                     DEUTNL2AXXX                                                         \\n                                         Place of settlement = CIKBBEBBXXX  \\n                                    \\n  \\n  \\nBULGARIA                      UNICREDIT BULBANK A.D                                         UNCRBGSFXXX  \\n                                         A/C 80000130515 (stock)  \\n                                         Place of settlement = CEDPBGSFXXX  \\n                                         Use Beneficiary BIC - DEUTGB22EEQ  \\n  \\n  \\nCANADA                          Royal Bank of Canada, Toronto                                     ROYCCAT2XXX  \\n                                         CUID RBCT   \\n                  A/C  080001890036 (stock)  \\n                                         Place of settlement = CDSLCATTXXX', metadata={'source': 'data/ssi-docs/db-ssi.pdf', 'page': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssi_pages)\n",
    "ssi_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=ssi_pages,\n",
    "    collection_name=\"ssi-docs\",\n",
    "    embedding=OllamaEmbeddings(),\n",
    "    collection_metadata={\"topic\":\"ssi docs\",\"source\": \"db-ssi.pdf\"},\n",
    "    persist_directory=\"./chroma_db_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llm-papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_loader = PyPDFLoader(\"data/llm-papers/openai-paper.pdf\")\n",
    "llm_pages = llm_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='Sparks of Artiﬁcial General Intelligence:\\nEarly experiments with GPT-4\\nS´ ebastien Bubeck Varun Chandrasekaran Ronen Eldan Johannes Gehrke\\nEric Horvitz Ece Kamar Peter Lee Yin Tat Lee Yuanzhi Li Scott Lundberg\\nHarsha Nori Hamid Palangi Marco Tulio Ribeiro Yi Zhang\\nMicrosoft Research\\nAbstract\\nArtiﬁcial intelligence (AI) researchers have been developing and reﬁning large language models (LLMs)\\nthat exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding\\nof learning and cognition. The latest model developed by OpenAI, GPT-4 [Ope23], was trained using an\\nunprecedented scale of compute and data. In this paper, we report on our investigation of an early version\\nof GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-\\n4 is part of a new cohort of LLMs (along with ChatGPT and Google’s PaLM for example) that exhibit\\nmore general intelligence than previous AI models. We discuss the rising capabilities and implications of\\nthese models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and diﬃcult\\ntasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any\\nspecial prompting. Moreover, in all of these tasks, GPT-4’s performance is strikingly close to human-level\\nperformance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of\\nGPT-4’s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version\\nof an artiﬁcial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis\\non discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more\\ncomprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond\\nnext-word prediction. We conclude with reﬂections on societal inﬂuences of the recent technological leap and\\nfuture research directions.\\nContents\\n1 Introduction 4\\n1.1 Our approach to studying GPT-4’s intelligence . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n1.2 Organization of our demonstration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n2 Multimodal and interdisciplinary composition 13\\n2.1 Integrative ability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n2.2 Vision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n2.2.1 Image generation beyond memorization . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n2.2.2 Image generation following detailed instructions (` a la Dall-E) . . . . . . . . . . . . . . 17\\n2.2.3 Possible application in sketch generation . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n2.3 Music . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n3 Coding 21\\n3.1 From instructions to code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n3.1.1 Coding challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n3.1.2 Real world scenarios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\n3.2 Understanding existing code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n1arXiv:2303.12712v5  [cs.CL]  13 Apr 2023', metadata={'source': 'data/llm-papers/openai-paper.pdf', 'page': 0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_pages)\n",
    "llm_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=llm_pages,\n",
    "    collection_name=\"llm-papers\",\n",
    "    embedding=OllamaEmbeddings(),\n",
    "    collection_metadata={\"topic\":\"llm papers\",\"source\": \"openai-paper.pdf\"},\n",
    "    persist_directory=\"./chroma_db_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mchroma_db_test/\u001b[0m\n",
      "├── \u001b[01;34m25a646c7-4f14-470b-95a5-80304c9f1d6f\u001b[0m\n",
      "│   ├── data_level0.bin\n",
      "│   ├── header.bin\n",
      "│   ├── length.bin\n",
      "│   └── link_lists.bin\n",
      "├── \u001b[01;34m5783fbcf-95ef-40d5-9ef2-57935e07ecb2\u001b[0m\n",
      "│   ├── data_level0.bin\n",
      "│   ├── header.bin\n",
      "│   ├── length.bin\n",
      "│   └── link_lists.bin\n",
      "├── chroma.sqlite3\n",
      "└── \u001b[01;34me581d79b-7adc-45ee-b8e6-635022156c2e\u001b[0m\n",
      "    ├── data_level0.bin\n",
      "    ├── header.bin\n",
      "    ├── length.bin\n",
      "    └── link_lists.bin\n",
      "\n",
      "3 directories, 13 files\n"
     ]
    }
   ],
   "source": [
    "!tree chroma_db_test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=system-documentation),\n",
       " Collection(name=llm-papers),\n",
       " Collection(name=ssi-docs)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(\"./chroma_db_test\")\n",
    "\n",
    "persistent_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-lab-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
